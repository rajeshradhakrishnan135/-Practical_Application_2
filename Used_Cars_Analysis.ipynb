{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from Kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications, we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to find the features/attributes of a used car that determine it's price. The task involves  creating multiple regression models of the features (X) with the price (y) and evaluating the coefficients of the model. The  statistics of root mean squared error will be used to hone in on the best model to use on the entire dataset. The regression results will further tell us the importance of the features in determining the price of the used car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps to get to know the dataset involve getting the descriptive statistics of the dataset, determining the categorical features from the numeric features and looking for missing data. Any features with a large number of missing data can be dropped whereas null records from the other fields can be removed before proceeding to the data analysis stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, PolynomialFeatures, OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df = pd.read_csv('data/vehicles.csv')\n",
    "cars_df_original = cars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null values\n",
    "cars_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region, price and state have no missing data, plotting them\n",
    "cars_df_to_plot = cars_df.loc[cars_df['price'] > 0]\n",
    "px.box(x=np.log10(cars_df_to_plot['price']),y=cars_df_to_plot['state']).update_layout(\n",
    "    title=\"BoxPlot of log10(price) by state\", xaxis_title=\"log10(price)\", yaxis_title=\"state\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "cars_df['state'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('states')\n",
    "plt.ylabel('Number of records')\n",
    "plt.title('Number of used-car records by state')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of odometer versus price\n",
    "cars_df_price_odo = cars_df[(cars_df['price'] <= 1000000) & (cars_df['odometer'] <= 1000000)]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.scatterplot(data=cars_df_price_odo,x='odometer',y='price')\n",
    "plt.title('ScatterPlot of odometer vs price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of average price of car by manufacturer\n",
    "cars_df_manufacturer_price = cars_df[(cars_df['manufacturer'].notna()) & (cars_df['price'] > 0) & (cars_df['price'] <= 1000000)]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "cars_df_manufacturer_price.groupby('manufacturer')['price'].mean().sort_values().plot(kind='bar')\n",
    "plt.title('Average Price of used car by Manufacturer')\n",
    "plt.xlabel('Car Manufacturer')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price of used car by condition\n",
    "cars_df_to_plot = cars_df.loc[(cars_df['price'] > 0) & (cars_df['price'] <= 1000000) & (cars_df['condition'].notna())]\n",
    "px.box(x=np.log10(cars_df_to_plot['price']),y=cars_df_to_plot['condition']).update_layout(\n",
    "    title=\"BoxPlot of log10(price) by condition\", xaxis_title=\"log10(price)\", yaxis_title=\"condition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odometer vs Transmission\n",
    "cars_df_odo_transmission = cars_df[(cars_df['transmission'].notna()) & (cars_df['odometer'] > 0) & (cars_df['odometer'] <= 1000000)]\n",
    "px.box(x=np.log10(cars_df_odo_transmission['odometer']),y=cars_df_odo_transmission['transmission']).update_layout(\n",
    "    title=\"BoxPlot of log10(odometer) by transmission\", xaxis_title=\"log10(odometer)\", yaxis_title=\"transmission\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price vs Fuel\n",
    "cars_df_to_plot = cars_df.loc[(cars_df['price'] > 0) & (cars_df['price'] <= 1000000) & (cars_df['fuel'].notna())]\n",
    "px.box(x=cars_df_to_plot['fuel'],y=np.log10(cars_df_to_plot['price']),color_discrete_sequence=['gray']).update_layout(\n",
    "    title=\"BoxPlot of log10(price) by fuel\", xaxis_title=\"fuel\", yaxis_title=\"log10(price)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine-tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the id, VIN, model and size columns\n",
    "cars_df = cars_df.drop(['id','VIN','model','size'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where cylinders, condition, drive, paint_color, type, manufacturer, odometer, transmission are null\n",
    "cars_df = cars_df.loc[cars_df['cylinders'].notna()]\n",
    "cars_df = cars_df.loc[cars_df['condition'].notna()]\n",
    "cars_df = cars_df.loc[cars_df['drive'].notna()]\n",
    "cars_df = cars_df.loc[cars_df['paint_color'].notna()]\n",
    "cars_df = cars_df.loc[cars_df['type'].notna()]\n",
    "cars_df = cars_df.loc[cars_df['manufacturer'].notna()]\n",
    "cars_df = cars_df.loc[cars_df['odometer'].notna()]\n",
    "cars_df = cars_df.loc[cars_df['transmission'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove price and odometer records that are zero and also those larger than 1 million (to remove outliers)\n",
    "cars_df = cars_df[(cars_df['price'] > 0) & (cars_df['price'] <= 1000000)]\n",
    "cars_df = cars_df[(cars_df['odometer'] > 0) & (cars_df['odometer'] <= 1000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of records retained for analysis\n",
    "total_records_in_original_dataset = cars_df_original.shape[0]\n",
    "print('Percent of records for the analysis =',np.round((cars_df.shape[0]/total_records_in_original_dataset)*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr heatmap - between price, year and odometer\n",
    "corr = cars_df[['price','year','odometer']].corr()\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(corr,annot=True,cmap='coolwarm')\n",
    "plt.title('Correlation between price, year and odometer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate the X and y values\n",
    "X = cars_df.drop('price', axis = 1)\n",
    "y = cars_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split into training and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor - dummy variables for categorical features and scaling numerical features\n",
    "num_features = ['year','odometer']\n",
    "cat_features = ['region','manufacturer','condition','cylinders','fuel', \\\n",
    "                'title_status','transmission','drive','type','paint_color','state']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_features', make_pipeline(StandardScaler(), PolynomialFeatures(degree=3, include_bias=False)), num_features),\n",
    "        ('cat_features', make_pipeline(OneHotEncoder(handle_unknown='ignore')), cat_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipleline for modeling with LinearRegression\n",
    "pipe_lin_reg = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('linreg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = pipe_lin_reg.predict(X_train)\n",
    "test_preds = pipe_lin_reg.predict(X_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "print('RMSE train =',np.round(rmse_train,2),'and RMSE test =',np.round(rmse_test,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of the model and feature names\n",
    "with pd.option_context('display.max_rows', None,):\n",
    "    print(pd.DataFrame(pipe_lin_reg.named_steps['linreg'].coef_, index = pipe_lin_reg.named_steps['preprocessor'].get_feature_names_out()).rename(columns = { 0 : \"coeff\"}).sort_values(by = \"coeff\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lin_reg.named_steps['linreg'].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-squared and adjusted r-squared\n",
    "r2 = r2_score(y_test, test_preds)\n",
    "adj_r2 = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "print(\"r_squared =\",np.round(r2,4),'and adjusted r-squared =',np.round(adj_r2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation importance of the features\n",
    "results = permutation_importance(pipe_lin_reg, X_test, y_test)\n",
    "importances = pd.DataFrame(data=results.importances_mean, index=X_test.columns, columns=['Importance']).sort_values(by='Importance', ascending=False)\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results from the Linear Regression model show that year of the car and the odometer are the most important features, \n",
    "# followed by number of cylinders, fuel, type and manufacturer, in determining the price of a used car. The transmission and \n",
    "# paint color affect the price of the used car the least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) Ridge Regression (with 10-fold cross-validation) ; Note: takes more than a minute to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipleline for modeling with RidgeRegression\n",
    "pipe_ridge_reg = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('ridge', Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ridge_alpha_dict = {'ridge__alpha': [0.01, 0.1, 1.0, 10.0, 100.0], 'ridge__fit_intercept': [True,False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ridge = GridSearchCV(pipe_ridge_reg, param_grid=param_ridge_alpha_dict, cv=10)\n",
    "grid_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best Alpha chosen: {list(grid_ridge.best_params_.values())[0]}')\n",
    "print(f'Fit_Intercept chosen: {list(grid_ridge.best_params_.values())[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = grid_ridge.best_estimator_.predict(X_train)\n",
    "test_preds = grid_ridge.best_estimator_.predict(X_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "print('RMSE train =',np.round(rmse_train,2),'and RMSE test =',np.round(rmse_test,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-squared and adjusted r-squared\n",
    "r2 = r2_score(y_test, test_preds)\n",
    "adj_r2 = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "print(\"r_squared =\",np.round(r2,4),'and adjusted r-squared =',np.round(adj_r2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) Sequential Feature Selection ; Note: takes more than 3 minutes to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipleline for modeling using LinearRegression with Sequential Feature Selection\n",
    "selector = SequentialFeatureSelector(LinearRegression(), n_features_to_select=5)\n",
    "\n",
    "pipe_lin_reg_seq = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('column_selector', selector),    \n",
    "    ('linreg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lin_reg_seq.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = pipe_lin_reg_seq.predict(X_train)\n",
    "test_preds = pipe_lin_reg_seq.predict(X_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "print('RMSE train =',np.round(rmse_train,2),'and RMSE test =',np.round(rmse_test,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lin_reg_seq.named_steps['linreg'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lin_reg_seq.named_steps['column_selector'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pipe_lin_reg_seq.named_steps['preprocessor'].get_feature_names_out()).loc[[0,1,4,467,482],0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high-quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight into drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Therefore, best model (based on lowest mse and highest adj r-squared) = Linear Regression model, fit it on entire X data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = pipe_lin_reg\n",
    "best_model.fit(X,y)\n",
    "y_preds = best_model.predict(X)\n",
    "rmse = np.sqrt(mean_squared_error(y, y_preds))\n",
    "print('RMSE using entire dataset =',np.round(rmse,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-squared and adjusted r-squared\n",
    "r2 = r2_score(y, y_preds)\n",
    "adj_r2 = 1 - (1-r2)*(len(y)-1)/(len(y)-X.shape[1]-1)\n",
    "print(\"r_squared = \",np.round(r2,4),'and adjusted r-squared =',np.round(adj_r2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of the model and feature names (based on sign and magnitude of the coeff, we can infer its effect on price)\n",
    "with pd.option_context('display.max_rows', None,):\n",
    "    print(pd.DataFrame(best_model.named_steps['linreg'].coef_, index = best_model.named_steps['preprocessor'].get_feature_names_out()).rename(columns = { 0 : \"coeff\"}).sort_values(by = \"coeff\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance of the features\n",
    "results = permutation_importance(best_model, X, y)\n",
    "importances = pd.DataFrame(data=results.importances_mean, index=X.columns, columns=['Importance']).sort_values(by='Importance', ascending=False)\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine-tuning their inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset of the attributes of about 426,000 used cars and their respective prices was analyzed to determine the importance of these features in its sale price.\n",
    "\n",
    "The regression analysis reveals that the most important feature in determining the price of a used car is the year of the car (closer the year is to the present year, higher the price of the used car). The second is the miles driven as given by the odometer reading (higher implies a lower price) and the third is the number of cylinders of the engine (higher implies a higher price). The year is more than twice as important than the odometer reading in affecting the price.\n",
    "\n",
    "It was found that cars from manufacturers such as Ferrari, Tesla, Aston-Martin and Porsche have much higher priced cars (which is not a surprise since they are luxury car brands). The car brands of Fiat, Dodge, Nissan, Kia and Chrysler are at the other end of the spectrum with the lowest prices. The condition of the car also affects the price, that is cars which are in excellent, new, like-new or good condition command a higher price than those of fair or salvage condition. A clean title status also helps in increasing the price commanded by the used car, whereas a missing title adversely impacted the price. In terms of region, Southwest VA, Texarkana TX, Susanville CA, Panama City, FL and Heartland Florida commanded a higher price for a used car (compared to other regions in the country). The states of NC, UT, NE, NV and WA had higher used car prices compared to other states.\n",
    "\n",
    "And in terms of fuel, diesel fuel cars were priced higher than gas fuel, electric or hybrid cars. The paint color is the least important feature followed by transmission type, and they have a negligible impact on the price of the car.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
